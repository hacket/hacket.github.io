---
date_created: Friday, February 23rd 2016, 10:10:45 pm
date_updated: Thursday, January 30th 2025, 9:37:52 am
title: Binder
author: hacket
categories:
  - Android Framework
category: Framework基础
tags: [Binder, Framework基础]
toc: true
description: 
dg-publish: true
dg-enable-search: true
dg-show-local-graph: true
dg-show-toc: true
dg-show-file-tree: true
image-auto-upload: true
feed: show
format: list
date created: 2024-12-24 00:39
date updated: 2024-12-24 00:39
aliases: [Binder]
linter-yaml-title-alias: Binder
---

# Binder

## 1、Binder 是什么？

Binder 是 Android 最主要的 IPC 通信机制。

- 从**IPC**的角度看，Binder 是 Android 中的一种跨进程通信的机制，Linux 中没有，Android 独有；
- 从** Server 进程**的角度看，Binder 指的是 Server 中的 Binder 实体对象；
- 从 **Client 进程**的角度看，Binder 指的是对 Binder 代理对象，是 Binder 实体对象的一个远程代理
- 从**传输过程**的角度看，Binder 是一个可以跨进程传输的对象；Binder 驱动会对这个跨越进程边界的对象对一点点特殊处理，自动完成代理对象和本地对象之间的转换。

## 2、Linux 已有的 IPC 机制

**管道**<br />
半双工，单向的，一般是在父子进程之间使用。<br />使用 `pipe(fds)` 创建文件对应的管道，然后使用 write、read、close 方法操作这个管道。

> 低版本 Looper::Looper

**Socket**<br />
全双工，即可读又可写，两个进程之间无需存在亲缘关系

> Zygote 孵化应用进程

**共享内存**<br />
很快，0 次拷贝，进程之间无需存在亲缘关系

> MemoryFile 使用了 mmap 映射了匿名共享内存

**信号**<br />
单向的，发出去之后怎么处理是别人的事，知道进程 pid 就能发信号，也可以一次给一群进程发信号，但是只能带个信号，不能带别的参数

> Process.killProcess 发送了 SIGNAL_KILL 信号；
> Zygote 启动子进程后，需要关注子进程退出了没有，如果子进程退出了，Zygote 需要发送 SIGCHLD 信号及时把它回收掉。

## 3、为什么不用已有的 IPC 机制，而是新起一个新的 Binder

- [ ] [为什么 Android 要采用 Binder 作为 IPC 机制？](https://www.zhihu.com/question/39440766/answer/89210950)

### 传输效率高：Binder 的传输效率和可操作性很好

传输效率主要影响因素是内存拷贝次数，拷贝次数越少，传说速率越高。

1. 消息队列、Socket 和管道，数据先从发送方的缓存区拷贝到内核开辟的缓存区，再从内核缓存区拷贝到接收方的缓存区，需要 2 次拷贝
2. 共享内存呢，虽然使用它进行 IPC 通信时进行的内存拷贝次数是 0。但是共享内存操作复杂，也将它排除。
3. 采用 Binder 机制的话，则只需要经过 1 次内存拷贝即可。即从发送方的缓存区拷贝到内核的缓存区，而接收方的缓存区与内核的缓存区是映射到同一块物理地址的，因此只需要 1 次拷贝即可。

### 稳定性好

- 共享内存性能优于 Binder，但共享内存需要处理并发同步问题，容易出现死锁和资源竞争，稳定性较差
- Socket 虽然基于 C/S 架构，但是它主要是用于网络间的通信，传输效率较低
- Binder 基于 C/S 架构，Server 端和 Client 端相对独立，稳定性较好

### 安全性高：Binder 机制的安全性很高

传统 IPC 没有任何安全措施，完全依赖上层协议来确保。传统 IPC 的接收方无法获得对方进程可靠的 UID/PID(用户 ID/进程 ID)，从而无法鉴别对方身份。<br />

而 Binder 机制则为每个进程分配了 UID/PID 来作为鉴别身份的标示，并且在 Binder 通信时会根据 UID/PID 进行有效性检测。在实际项目中可能一些敏感的服务，不希望被乱用就可以通过 UID/PID 鉴权的方式来防护。<br />

**为什么说 Binder 是安全的？**<br />
在数据传输过程中有身份的校验，通过 UID、PID 进行校验

## Binder 架构

![rfbhs](https://raw.githubusercontent.com/hacket/ObsidianOSS/master/obsidian/rfbhs.png)

- **Java 层** 有一套 binder C/S 架构，通过 JNI 技术，与 Native 的 Binder 对应，Java 层的 Binder 的功能最终都是交给 Native 的 Binder 来完成
- **Native 层**有一整套完整的 Binder 通信的 C/S 架构，BPBinder 作为 Client，BBinder 作为 Server
- **Binder 驱动层 **

### Binder 驱动

**Binder 驱动不是 Linux 内核的一部分，它怎么做到能访问内核空间的呢？**<br />通过 Linux 的动态可加载内核模块（LKM Loadable Kernel Module），它在运行时被链接到内核作为内核的一部分在内核空间运行，用户进程之间通过这个模块作为桥梁，就可以完成通信了。<br />**Binder 是什么？**<br />Binder 驱动实际上和硬件设备没有任何关系，只是实现方式和设备驱动程序是一样的，它工作于内核态，提供 open()，mmap()，poll()，ioctl() 等标准文件操作，以字符驱动设备中的 misc 设备注册在设备目录/dev 下，用户通过/dev/binder 访问它。

## **Binder 通信模型**

![x87o9](https://raw.githubusercontent.com/hacket/ObsidianOSS/master/obsidian/x87o9.webp)

**Binder 模型中的组件：**<br />
Binder 是基于 C/S 架构的，由一系列组件组成，包括 Client、Server、ServiceManager 和 Binder 驱动；其中 Client、Server 和 ServiceManager 运行在用户空间，Binder 驱动运行在内核空间；其中 ServiceManager 和 Binder 驱动由系统提供，Client 和 Server 由应用程序来实现；Client、Server 和 ServiceManager 都是通过系统调用 open、mmap 和 ioctl 来访问设备文件/dev/binder，从而实现与 Binder 驱动的交互来间接的实现跨进程通信。

- Server 提供服务的进程
- Client 使用服务的进程
- ServiceManager 管理 Service 的注册和查询（将字符串形式的 Binder 名字转化成 Client 中对该 Binder 的引用）
- Binder 驱动 一个虚拟设备驱动，工作在内核态，提供 open、mmap 和 ioctl 等标准文件操作；Binder 驱动负责进程之间 Binder 通信的建立，Binder 在进程之间的传递，Binder 引用计数管理，数据包在进程之间的传递和交换等一系列底层支持。

**Binder 通信过程：**

1. 一个进程使用 `BINDER_SETCONTENT_MGR` 命令通过 Binder 驱动将自己注册成为 ServiceManager
2. **Server 注册** Server 进程通过 Binder 驱动向 ServiceManager 中注册 Binder（Server 中的 Binder 实体），表明可以对外提供服务。Binder 驱动为这个 Binder 创建位于内核中的实体节点以及 ServiceManager 对实体的引用，将名字以及新建的引用打包传给 ServiceManager，ServiceManager 将其填入查找表

> 注册的过程就是向 Binder 驱动的全局链表 `binder_procs` 中插入服务端的信息，然后向 service_manager 的 `svcinfo` 列表中缓存一下注册的服务

3. Client 进程通过名字在 Binder 驱动的帮助下从 ServiceManager 中获取到对 Binder 实体的引用，通过这个引用就能实现和 Server 进程的通信

![3lzty](https://raw.githubusercontent.com/hacket/ObsidianOSS/master/obsidian/3lzty.png)

## servicemanager

### servicemanager 启动流程

![5czg2](https://raw.githubusercontent.com/hacket/ObsidianOSS/master/obsidian/5czg2.png)<br />当 Kernel 启动加载完驱动之后，会启动 Android 的 init 程序，init 进程加载了 servicemanager 的 rc 可执行程序之后加载了 servicemanager 的入口函数启动了 servicemanager 进程。<br />servicemanager 启动分为三步：

1. 首先打开 Binder 驱动创建全局链表 `binder_procs`
2. 将自己当前进程信息保存到 binder_procs 链表
3. 开启 binder_loop 不断地处理共享内存中的数据，并处理 BR_xxx 命令

### servicemanager 作用？

- binder 机制的守护进程，Binder 上下文管理者（其他调用者通过**预留的 0 号引用**获取 servicemanager 的 binder）；
- 注册服务（针对 Server）
- 查询服务（针对 Client）

#### ServiceManager 注册服务

![wsacc](https://raw.githubusercontent.com/hacket/ObsidianOSS/master/obsidian/wsacc.png)

- 通过 ServiceManager 的 addService() 方法来注册服务
- ServiceManager 向 Binder 驱动发送 `BC_TRANSACTION` 命令 (ioctl 的命令，BC 可以理解为 Binder Client 发过来的请求命令) 携带 `ADD_SERVICE_TRANSACTION` 命令，同时注册服务的线程进入等待状态 `waitForResponse()`
- Binder 驱动收到请求命令向 ServiceManager 的 todo 队列里面添加一条注册服务的事务，事务的任务就是创建服务端进程 binder_node 信息并插入到 binder_procs 链表中
- 事务处理完之后发送 `BT_TRANSACTION` 命令，ServiceManager 收到命令后向 `svcinfo` 列表中添加已经注册的服务，最后发送 `BR_REPLY` 命令唤醒等待的线程，通知注册成功

#### ServiceManager 获取服务

![72q8w](https://raw.githubusercontent.com/hacket/ObsidianOSS/master/obsidian/72q8w.png)

- 通过 ServiceManager 的 getService() 方法来注册服务
- ServiceManager 向 binder 驱动发送 `BC_TRANSACTION` 命令携带 `CHECK_SERVICE_TRANSACTION` 命令，同时获取服务的线程进入等待状态 `waitForResponse()`
- Binder 驱动收到请求命令向 ServiceManager 发送 `BC_TRANSACTION` 查询已注册的服务，查询到直接响应 `BR_REPLY` 唤醒等待的线程；若查询不到将与 binder_procs 链表中的服务进行一次通讯再响应

### servicemanager 一些疑问？

#### Client 和 Server 怎么获取 servicemanager 的 binder 对象？

通过 `getStrongProxyForHandle(0)` 方法获取，因为 servicemanager 默认就是 0 号引用，便于其它系统服务查询使用，它内部会根据句柄创建对应的 BpBinder 对象

## Binder 原理

### binder_mmap(文件描述符，用户虚拟内存空间)

> binder 进程间通信效率高的核心机制：在内核虚拟地址空间，申请一块与用户虚拟内存相同大小的内存；然后再申请 1 个 page 大小的物理内存，再将同一块物理内存分别映射到内核虚拟地址空间和用户虚拟内存空间，从而实现了用户空间的 buffer 和内核空间的 buffer 同步操作的功能。

![pzjvs](https://raw.githubusercontent.com/hacket/ObsidianOSS/master/obsidian/pzjvs.png)<br />binder_mmap 通过**加锁**，保证一次只有一个进程分配内存，保证多进程间的并发访问。<br />虚拟进程地址空间 (vm_area_struct) 和虚拟内核地址空间 (vm_struct) 都映射到同一块物理内存空间，当 C 与 S 发送数据时，C 先从自己的进程空间把 IPC 通信数据 _copy_from_user_ 拷贝到内核空间，而 S 端与内核共享数据，不再需要拷贝数据，而是通过内存地址空间的偏移量，即可获悉内存地址，整个过程只发生一次内存拷贝。<br />进程和内核虚拟地址映射到同一个物理内存的操作是发生在数据接收端 (Server)，而数据发送端 (Client) 还是需要将用户态的数据拷贝到内核态。<br />Binder 在进程间数据通信的流程图：Binder 的内存转移关系。<br />![f2zsj](https://raw.githubusercontent.com/hacket/ObsidianOSS/master/obsidian/f2zsj.png)

### Binder 原理

**Binder 驱动：**Binder 驱动运行在内核空间，负责各个用户进程的通信；Binder 不是 Linux 系统内核的一部分，但 Linux 的**动态内核可加载模块**的机制，Android可动态添加一个内核模块运行在内核空间。<br />**内存映射**：内存映射是通过 mmap() 来实现的，将用户空间的一块内存区域映射到内核空间，映射关系建立后，用户对这块内存区域的修改可以直接反应到内核空间；反之内核空间对这段区域的修改也能直接反应到用户空间；内存映射减少了数据拷贝次数。<br />**Binder IPC 实现原理**<br />Binder IPC 基于内存映射来实现的。Binder IPC 原理通信如下；

1. 首先 Binder 驱动在内核空间创建一个数据接收缓存区
2. 接着在内核空间开辟一块内核缓存区，建立**内核缓存区**和**内核中数据接收缓存区**之间的映射关系，以及**内核中数据接收缓存区**和**接收进程用户空间地址**的映射关系
3. 发送方进程通过系统调用 _copy_from_user()_ 将数据 copy 到内核中的内核缓存区，由于内核缓存区和接收进程的用户空间存在映射关系，因此也就相当于把数据发送到了接收进程的用户空间，这样便完成了一次进程间的通信

![k4619](https://raw.githubusercontent.com/hacket/ObsidianOSS/master/obsidian/k4619.webp)

### Binder 进程和线程

![hjzi2](https://raw.githubusercontent.com/hacket/ObsidianOSS/master/obsidian/hjzi2.png)<br />**进程**<br />底层 Binder 驱动，通过 `binder_procs` 链表记录所有创建的 Binder_proc 结构体，Binder 驱动层的每一个 binder_proc 结构体都与用户空间的一个用于 Binder 通信的进程一一对应，且每个进程有且只有一个 ProcessState 对象，这是通过单例模式来保证的，每个进程中可以有很多个线程，每个线程对应一个 IPCThreadState 对象，IPCThreadState 对象也是单例模式，即一个线程对应一个 IPCThreadState 对象，在 Binder 驱动对应 _binder_thread_ 结构体，在 binder_proc 结构体中通过成员变量 rb_root_threads 来记录当前进程内所有的 binder_thread<br />**Binder 线程池**<br />每个 Server 进程在启动时会创建一个 Binder 线程池，会注册一个 Binder 线程；后续 Server 进程可以向 Binder 线程池注册新的线程，Binder 驱动在探测到没有空闲线程时也会主动向 Server 进程注册 Binder 线程。<br />一个 Server 进程默认最多 16 个 Binder 线程

## AIDL

### 什么是 AIDL？

AIDL 是 Android Interface definition language 的缩写，它是一种 Android 内部进程通信接口的描述语言，通过它我们可以定义进程间的通信接口。

### AIDL in out inout oneway

#### in out inout

1. in 参数使得实参顺利传到服务方，但服务方对实参的任何改变，不会反应给调用方
2. out 参数使得实参不会真正传递到服务方，只是传一个实参的初始值过去，但服务方对实参的任何改变，在调用结束后会反应回调用方
3. inout 是上面二者的结合，实参会顺利传到服务方，且服务方对实参的任何改变，在调用结束后会反应回调用方

> 其实 inout，都是相对于服务方，in 参数使得实参传到了服务方，所以是 in 进入了服务方，out 参数使得实参在调用结束后从服务方传回给调用方，所以 out 是从服务方出来

#### oneway

oneway 主要有两个特性：**异步调用**和**串行化处理**。

- 异步调用是指应用向 binder 驱动发送数据后不需要挂起线程等待 binder 驱动的回复，而是直接结束。像一些系统服务调用应用进程的时候就会使用 oneway，比如 AMS 调用应用进程启动 Activity，这样就算应用进程中做了耗时任务，也不会阻塞系统服务的运行
- 串行化处理是指对于一个服务端的 AIDL 接口而言，所有的 oneway 方法不会同时执行，binder 驱动会将它们串行化处理，排队一个一个调用

**非 oneway 情况：**<br />非 oneway 的话，Client 会挂起，相当于 Thread 的 sleep，底层调用的是 `wait_event_interruptible()`Linux 系统函数。<br />![zrz96](https://raw.githubusercontent.com/hacket/ObsidianOSS/master/obsidian/zrz96.png)<br />**oneway 情况：**<br />oneway 的话，Client 就不需要挂起线程等待<br />![pkeay](https://raw.githubusercontent.com/hacket/ObsidianOSS/master/obsidian/pkeay.png)

# 面试题

## Binder 相关问题

### Binder 线程数？

默认为 16 个 Binder 线程

### Zygote 孵化进程的 IPC 机制用 Socket 而不用 Binder？为什么？

**为什么不用 Binder？**

1. zygote 在 fork 时，它会保持自己为单线程状态，这是因为多线程下的 fork 很容易在子进程中产生死锁、状态紊乱等一系列问题，根本原因是因为即便父进程为多线程，fork 之后的子进程也只会有一个线程，这种多对一的转换会遗漏掉很多同步的信息
2. 19 年邮件咨询过 Google 负责 Binder 的两位工程师，因为 Binder 压根就不支持 fork，除非 fork 后调用 exec 开启全新的进程环境，这主要是因为 Binder 中对象生命周期的管理比较复杂，而如果为了支持 fork，那么它的设计将会更加复杂
3. zygote 和 systemserver 本就是父子关系，对于简单的消息通信，用管道或者 socket 非常方便。

**为什么不 fork system_server？**<br />
如果 zygote 用了 binder 机制，再 fork systemServer，那 systemServer 就继承了 zygote 的描述符和映射的内存，这两个进程在 binder 驱动层就会共用一套数据结构，这肯定是不行的。那还得把旧的描述符关掉，再重新启动一遍 binder 机制，自找麻烦。

### ServiceManager

#### Client、Server 和 ServiceManager 之间怎么通信的？

Client、Server 和 ServiceManager 它们都是在不同的进程中，它们之间通信通过 Binder IPC 机制。Server 提供服务给 Client 使用，这个服务是以 Binder 引用的形式提供的。那么 Client 如何拿到 Server 的 Binder 的引用呢？<br />从 ServiceManager 中拿，ServiceManager 也是一个单独的进程，那么 Client 和 Server 如何与 ServiceManager 进行通信呢？这就陷入了先有鸡还是先有蛋的死循环了。<br />其实 Client、Server 和 ServiceManager 之间都是通过 Binder 通信的，只是 ServiceManager 作为特殊的 Binder(handle=0) 提前放入了 Binder 驱动里，Client 和 Server 想要获取 ServiceManager 的 Binder 引用，只需要获取 handle=0 的 Binder 即可。

#### servicemanager 进程和 Binder 驱动

servicemanager 是用户空间的守护进程，它会在启动时和 Binder 驱动进行通信；<br />它会在 Binder 驱动新建 ServiceManager 对应的 Binder 实体，并将该 Binder 实体设置为全局变量。<br />

**为什么要设置为全局的？**<br />

因为 Client 和 Server 都需要和 ServiceManager 进行通信，不设置为全局的，怎么找到 servicemanager。

#### ServiceManager 如何注册为 binder 上下文管理者的？

ServiceManager 提供的 Binder 比较特殊，它**没有名字也不需要注册**，当一个进程使用 `BINDER_SET_CONTEXT_MGR` 命令将自己注册成 ServiceManager 时 Binder 驱动会**自动为它创建 Binder 实体**（这就是那只预先造好的鸡）。其次**这个 Binder 的引用在所有 Client 中都固定为 0**而无须通过其它手段获得。也就是说，一个 Server 若要向 ServiceManager 注册自己 Binder 就必需通过 0 这个引用号和 ServiceManager 的 Binder 通信。

### Android 中使用 binder 一定要用 service 吗？

### 什么是匿名 Binder、实名 Binder？匿名 Binder 的应用

- **实名 Binder** 在 ServiceManager 中注册了名字的 Binder 叫实名 Binder；
- **匿名 Binder** 未在 ServiceManager 注册了名字就是匿名 Binder，但必须通过实名 Binder 已经建立的 Binder 实体传递给 Client，Client 会收到这个匿名 Binder 的引用，通过这个引用向位于 Server 中的实体发送请求，匿名 Binder 为通信双方建立一条私密通道，只要 Server 没有把匿名 Binder 发送给其他进程，其他进程就无法通过穷举或猜测的方式获得该 Binder 的引用，向该 Binder 发送请求

### 什么是 oneway？**AIDL 的 oneWay 和非 oneway 有什么区别?**

oneway server 端是串行处理，异步调用，Client 端不用休眠等待驱动返回数据。

- 非 oneway

![w5607](https://raw.githubusercontent.com/hacket/ObsidianOSS/master/obsidian/w5607.png)

- oneway

![8749v](https://raw.githubusercontent.com/hacket/ObsidianOSS/master/obsidian/8749v.png)

- 在 AIDL 中写代码时，如果接口标记了 oneway，表示 Server 端**串行化处理 (从异步队列中拿出消息指令一个个分发)、异步调用**。这个关键字主要是用于修改远程调用的行为，就如上面的两个图一样。非 oneway 关键字的 AIDL 类，**客户端需要挂起线程等待休眠，相当于调用了 Sleep 函数**。例如 WMS 、AMS 等相关系统 Binder 调用都是 oneway 的。

### **Intent 跨进程传大图为什么会崩溃？**Binder 传输数据大小限制？1M？怎么突破？

常规的 intent 传递数据，在 startActivity 时将 Bundle 的 allowFds 设置成了 false（禁用了文件描述符）, 然后就会将 Bitmap 直接写到 Parcel 缓冲区，不能利用共享内存，导致缓冲区超限，触发异常。如果通过 bundle.putBinder 形式传递 Bitmap，避免了 Intent 禁用描述符的影响，会开辟一个块共享匿名内存用来存 Bitmap 的数据，而 Parcel 缓冲区只是存储 FD 。

#### Binder 传输 1M 限制

原因：官方**TransactionTooLargeException**的文档中描述到：Binder 事务缓冲区有一个有限的固定大小，目前为 1MB，由进程所有正在进行的事务共享。继续往下看。<br />

普通的应用是由 Zygote 孵化而来的用户进程，所映射的 Binder 内存大小是不到 1M 的，准确说是 1M-8K：`110241024) - (4096 *2) `：这个限制定义在 frameworks/native/libs/binder/processState.cpp 类中，如果传输数据超过这个大小，系统就会报错，因为 Binder 本身就是为了进程间频繁而灵活的通信所设计的，并不是为了拷贝大数据而使用的，所以当传递大的数据时会出现上述的错误：<br />

**解决** ：用 Intent.putBinder<br />如果通过 `bundle.putBinder` 形式传递 Bitmap，会开辟一个块共享匿名内存用来存 Bitmap 的数据，而 Parcel 缓冲区只是存储 FD 。

### Binder 只需要一次内存拷贝的原因？

底层用到了 mmap
